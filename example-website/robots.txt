# robots.txt for example-website

# Metadata for webcrawler
Payment-url: http://sky-services.xyz/receivers/crawler-paid-content/

# Directives for AI crawlers
User-agent: *
Disallow: /blog/
Paid-content: /products/
Payment: www.skyfire.xyz
