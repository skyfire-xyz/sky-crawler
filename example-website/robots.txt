# robots.txt for example-website

# Metadata for webcrawler
Payment-url: http://sky-services.xyz/receivers/crawler-paid-content/

# Directives for AI crawlers
User-agent: *
Paid-content: /blog/
Paid-content: /products/
